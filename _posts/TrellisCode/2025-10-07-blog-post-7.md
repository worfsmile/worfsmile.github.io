---
title: 'trellis3d-code - 踩坑记录&datatoolkit代码总结'
date: 2025-10-07
permalink: /posts/2025/10/blog-post-7/
tags:
series: TrellisCode
---

# Run Code for Trellis3D
踩坑记录&datatoolkit代码总结
=======

## datatoolkit

- 整体按照 Dataset.md 可以完成
- 安装对应的包可以完成运行
- 下载数据集巨大, 如ABO 154G
- 多线程中如果出现错误, 比如 `can't find module xx` 会卡在那里
- 每次跑完一个文件要跑一下 metadata
- 在Linux下运行注意np的数据类型, 注意要float32还是64或者是否需要将数据连续存储, 同时在 voxel 中容易 segment fault, 需要考虑平替方法
- 其中utils3d安装:pip install git+https://github.com/EasternJournalist/utils3d.git@9a4eb15e4021b67b12c460c7057d642626897ec8
- transfermers要用python3.10的环境

## datatoolkit-code

outdir = 'outdir'

1. metadata.py: 完成metadata的生成, 得到 outdir/metadata.csv
   1. 得到一个csv, 表头包括 sha256,file_identifier,aesthetic_score,captions,rendered,voxelized,num_voxels,cond_rendered,local_path,feature_dinov2_vitl14_reg,ss_latent_ss_enc_conv3d_16l8_fp16,latent_dinov2_vitl14_reg_slat_enc_swin8_B_64l8_fp16
   2. 逐步进行检测处理进度 True or False
   3. 表中的hash对应的是文件唯一标识, 用来快速索引和去重
   ```python
    sha256 = get_file_hash(os.path.join(output_dir, 'raw/3dmodels/original', instance))
    pbar.update()
    return sha256
    ```
2. download.py: 完成数据集的下载, 得到 outdir/raw
   1. `tar.extract(f"3dmodels/original/{instance}", path=os.path.join(output_dir, 'raw'))` 获得 `loc_path`
   2. 获得文件 `downloaded.to_csv(os.path.join(opt.output_dir, f'downloaded_{opt.rank}.csv'), index=False)`
3. render.py: 渲染不同视角的图片
   1. 根据 `views = [{'yaw': y, 'pitch': p, 'radius': r, 'fov': f} for y, p, r, f in zip(yaws, pitchs, radius, fov)]` 进行blender渲染
   2. 获得渲染结果 `/output_dir/render/`
   3. 获得文件 `rendered.to_csv(os.path.join(opt.output_dir, f'rendered_{opt.rank}.csv'), index=False)`
4. voxelize.py: 完成voxel化
   1. 获得处理后的点云 `write_ply(os.path.join(output_dir, 'voxels', f'{sha256}.ply'), vertices)`
   2. 其中保存的是被占据的体素的中心点的真实坐标(以去重)
5. extract_features.py: 完成特征提取
   1. 数据来源 `/output_dir/render/` 和 `os.path.join(output_dir, 'voxels', f'{sha256}.ply')`
   2. 获得每个体素的特征
   ```python
    def saver(sha256, pack, patchtokens, uv):   # 一对多的关系, 一个体素对应多个特征
    # pack: 顶点 position 所在的 induce 可能出现多次
    # patchtokens: 特征图
    # 三维到二维的映射 uv
        pack['patchtokens'] = F.grid_sample(    # 基于坐标网格对特征图进行采样
            patchtokens,
            uv.unsqueeze(1),    # 依赖于相机参数
            mode='bilinear',
            align_corners=False,
        ).squeeze(2).permute(0, 2, 1).cpu().numpy()
        pack['patchtokens'] = np.mean(pack['patchtokens'], axis=0).astype(np.float16)   # 特征平均
        save_path = os.path.join(opt.output_dir, 'features', feature_name, f'{sha256}.npz')
        np.savez_compressed(save_path, **pack)
        records.append({'sha256': sha256, f'feature_{feature_name}' : True})
   ```
   3. 获得文件 `save_path = os.path.join(opt.output_dir, 'features', feature_name, f'{sha256}.npz')`
6. encode_ss_latent.py: 完成空间特征编码
   1. 数据来源: `os.path.join(opt.output_dir, 'voxels', f'{instance}.ply')`
   2. `coords = ((torch.tensor(position) + 0.5) * opt.resolution).int().contiguous()` 获得 `ss[:, coords[:, 0], coords[:, 1], coords[:, 2]] = 1` 后, 模型直接嵌入ss
   3. 获得文件 `save_path = os.path.join(opt.output_dir, 'ss_latents', latent_name, f'{sha256}.npz')`
7. encode_latent.py: 完成隐空间特征编码
   1. 数据来源: `os.path.join(opt.output_dir, 'features', opt.feat_model, f'{sha256}.npz')`
   2. `load feat`: `feats = np.load(os.path.join(opt.output_dir, 'features', opt.feat_model, f'{sha256}.npz'))`
   3. `deal`: `latent = encoder(feats, sample_posterior=False)`
   4. 获得文件: `save_path = os.path.join(opt.output_dir, 'latents', latent_name, f'{sha256}.npz')`

## train vae

- `parser.add_argument('--node_rank', type=int, default=0, help='Node rank')`   # 这个不是0会出问题
- 需要 cuda118 来安装 mip-splatting/submodules/diff-gaussian-rasterization 同时需要 g++11 和 gml, 记得export一下
- 安装kaolin: pip install kaolin==0.18.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu124.html

## generate

- 下载spconv: `pip install spconv-cu118` (下载之前记得清理其他的spconv)

## ddpm

- 多卡同步问题, 在finish时会出现其他卡先结束但是主卡一直等待的问题, 解决方法是把finish改的和init一样
- 关于 `num_workers` 如果数量过多会带来不必要的开销
  ```python
  self.dataloader = DataLoader(
            self.dataset,
            batch_size=self.batch_size_per_gpu,
            # num_workers=int(np.ceil(os.cpu_count() / torch.cuda.device_count())),
            num_workers=2,
            pin_memory=True,
            drop_last=True,
            persistent_workers=True,
            collate_fn=functools.partial(self.dataset.collate_fn, split_size=self.batch_split),
            sampler=self.data_sampler,
        )
  ```

## 数据准备

- `Trainer.load_data()` 中如果数据集小于batch_size会出现死循环

## 模型

- 卷积输入: pytorch [B, C, H, W]

| 库/框架                      | 默认图像维度               | 说明                                       |
| ------------------------- | -------------------- | ---------------------------------------- |
| **OpenCV (cv2)**          | HWC                  | Height × Width × Channels，channels BGR顺序 |
| **PIL / Pillow**          | HWC                  | Height × Width × Channels，channels RGB顺序 |
| **Matplotlib**            | HWC                  | Height × Width × Channels，显示用通常RGB       |
| **TensorFlow / Keras**    | HWC (默认) 或 NHWC (批量) | NHWC = Batch × Height × Width × Channels |
| **PyTorch / torchvision** | CHW (单张) 或 NCHW (批量) | Channel × Height × Width，需要转换HWC → CHW   |
| **NumPy arrays**          | HWC (一般存储图片时)        | 可以自定义，但多数图像处理库读入后是HWC                    |
