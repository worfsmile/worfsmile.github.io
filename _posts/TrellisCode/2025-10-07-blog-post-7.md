---
title: 'trellis3d-code - 踩坑记录&datatoolkit代码总结'
date: 2025-10-07
permalink: /posts/2025/10/blog-post-7/
tags:
series: TrellisCode
---

# Run Code for Trellis3D
踩坑记录&datatoolkit代码总结
=======

## datatoolkit

- 整体按照 Dataset.md 可以完成
- 安装对应的包可以完成运行
- 下载数据集巨大, 如ABO 154G
- 多线程中如果出现错误, 比如 `can't find module xx` 会卡在那里
- 每次跑完一个文件要跑一下 metadata
- 在Linux下运行注意np的数据类型, 同时在 voxel 中容易 segment fault, 需要考虑平替方法
- 其中utils3d安装:pip install git+https://github.com/EasternJournalist/utils3d.git@9a4eb15e4021b67b12c460c7057d642626897ec8
- transfermers要用python3.10的环境

## datatoolkit-code

outdir = 'outdir'

1. metadata.py: 完成metadata的生成, 得到 outdir/metadata.csv
   1. 得到一个csv, 表头包括 sha256,file_identifier,aesthetic_score,captions,rendered,voxelized,num_voxels,cond_rendered,local_path,feature_dinov2_vitl14_reg,ss_latent_ss_enc_conv3d_16l8_fp16,latent_dinov2_vitl14_reg_slat_enc_swin8_B_64l8_fp16
   2. 逐步进行检测处理进度 True or False
   3. 表中的hash对应的是文件唯一标识, 用来快速索引和去重
   ```python
    sha256 = get_file_hash(os.path.join(output_dir, 'raw/3dmodels/original', instance))
    pbar.update()
    return sha256
    ```
2. download.py: 完成数据集的下载, 得到 outdir/raw
   1. `tar.extract(f"3dmodels/original/{instance}", path=os.path.join(output_dir, 'raw'))` 获得 `loc_path`
   2. 获得文件 `downloaded.to_csv(os.path.join(opt.output_dir, f'downloaded_{opt.rank}.csv'), index=False)`
3. render.py: 渲染不同视角的图片
   1. 根据 `views = [{'yaw': y, 'pitch': p, 'radius': r, 'fov': f} for y, p, r, f in zip(yaws, pitchs, radius, fov)]` 进行blender渲染
   2. 获得渲染结果 `/output_dir/render/`
   3. 获得文件 `rendered.to_csv(os.path.join(opt.output_dir, f'rendered_{opt.rank}.csv'), index=False)`
4. voxelize.py: 完成voxel化
   1. 获得处理后的点云 `write_ply(os.path.join(output_dir, 'voxels', f'{sha256}.ply'), vertices)`
   2. 其中保存的是被占据的体素的中心点的真实坐标(以去重)
5. extract_features.py: 完成特征提取
   1. 数据来源 `/output_dir/render/` 和 `os.path.join(output_dir, 'voxels', f'{sha256}.ply')`
   2. 获得每个体素的特征
   ```python
    def saver(sha256, pack, patchtokens, uv):   # 一对多的关系, 一个体素对应多个特征
    # pack: 顶点 position 所在的 induce 可能出现多次
    # patchtokens: 特征图
    # 三维到二维的映射 uv
        pack['patchtokens'] = F.grid_sample(    # 基于坐标网格对特征图进行采样
            patchtokens,
            uv.unsqueeze(1),    # 依赖于相机参数
            mode='bilinear',
            align_corners=False,
        ).squeeze(2).permute(0, 2, 1).cpu().numpy()
        pack['patchtokens'] = np.mean(pack['patchtokens'], axis=0).astype(np.float16)   # 特征平均
        save_path = os.path.join(opt.output_dir, 'features', feature_name, f'{sha256}.npz')
        np.savez_compressed(save_path, **pack)
        records.append({'sha256': sha256, f'feature_{feature_name}' : True})
   ```
   3. 获得文件 `save_path = os.path.join(opt.output_dir, 'features', feature_name, f'{sha256}.npz')`
6. encode_ss_latent.py: 完成空间特征编码
   1. 数据来源: `os.path.join(opt.output_dir, 'voxels', f'{instance}.ply')`
   2. `coords = ((torch.tensor(position) + 0.5) * opt.resolution).int().contiguous()` 获得 `ss[:, coords[:, 0], coords[:, 1], coords[:, 2]] = 1` 后, 模型直接嵌入ss
   3. 获得文件 `save_path = os.path.join(opt.output_dir, 'ss_latents', latent_name, f'{sha256}.npz')`
7. encode_latent.py: 完成隐空间特征编码
   1. 数据来源: `os.path.join(opt.output_dir, 'features', opt.feat_model, f'{sha256}.npz')`
   2. `load feat`: `feats = np.load(os.path.join(opt.output_dir, 'features', opt.feat_model, f'{sha256}.npz'))`
   3. `deal`: `latent = encoder(feats, sample_posterior=False)`
   4. 获得文件: `save_path = os.path.join(opt.output_dir, 'latents', latent_name, f'{sha256}.npz')`

## train

- 需要 cuda118 来安装 mip-splatting/submodules/diff-gaussian-rasterization 同时需要 g++11 和 gml, 记得export一下
- 安装kaolin: pip install kaolin==0.18.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu124.html
