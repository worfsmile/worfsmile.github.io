---
title: 'trellis3d-code DDPM'
date: 2025-10-11
permalink: /posts/2025/10/blog-post-11/
tags:
series: TrellisCode
---

DDPM
======

## 多卡训练

```python
import os
import io
from contextlib import contextmanager
import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP


def setup_dist(rank, local_rank, world_size, master_addr, master_port):
    os.environ['MASTER_ADDR'] = master_addr
    os.environ['MASTER_PORT'] = master_port
    os.environ['WORLD_SIZE'] = str(world_size)
    os.environ['RANK'] = str(rank)
    os.environ['LOCAL_RANK'] = str(local_rank)
    torch.cuda.set_device(local_rank)
    dist.init_process_group('nccl', rank=rank, world_size=world_size)
    

def read_file_dist(path):
    """
    Read the binary file distributedly.
    File is only read once by the rank 0 process and broadcasted to other processes.

    Returns:
        data (io.BytesIO): The binary data read from the file.
    """
    if dist.is_initialized() and dist.get_world_size() > 1:
        # read file
        size = torch.LongTensor(1).cuda()
        if dist.get_rank() == 0:
            with open(path, 'rb') as f:
                data = f.read()
            data = torch.ByteTensor(
                torch.UntypedStorage.from_buffer(data, dtype=torch.uint8)
            ).cuda()
            size[0] = data.shape[0]
        # broadcast size
        dist.broadcast(size, src=0)
        if dist.get_rank() != 0:
            data = torch.ByteTensor(size[0].item()).cuda()
        # broadcast data
        dist.broadcast(data, src=0)
        # convert to io.BytesIO
        data = data.cpu().numpy().tobytes()
        data = io.BytesIO(data)
        return data
    else:
        with open(path, 'rb') as f:
            data = f.read()
        data = io.BytesIO(data)
        return data
    

def unwrap_dist(model):
    """
    Unwrap the model from distributed training.
    """
    if isinstance(model, DDP):
        return model.module
    return model


@contextmanager
def master_first():
    """
    A context manager that ensures master process executes first.
    """
    if not dist.is_initialized():
        yield
    else:
        if dist.get_rank() == 0:
            yield
            dist.barrier()
        else:
            dist.barrier()
            yield
            

@contextmanager
def local_master_first():
    """
    A context manager that ensures local master process executes first.
    """
    if not dist.is_initialized():
        yield
    else:
        if dist.get_rank() % torch.cuda.device_count() == 0:
            yield
            dist.barrier()
        else:
            dist.barrier()
            yield
```

## 极简DDPM

```python
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel as DDP
import torch.multiprocessing as mp

# 上面的工具函数
from dist_utils import setup_dist, read_file_dist, master_first, unwrap_dist

class SimpleDDPM(nn.Module):
    def __init__(self, dim=16):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, 64),
            nn.ReLU(),
            nn.Linear(64, dim)
        )

    def forward(self, x, t=None):
        return self.net(x)

class DummyDataset(Dataset):
    def __init__(self, N=1024, dim=16):
        self.data = torch.randn(N, dim)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

def train_ddpm(rank, cfg):
    local_rank = rank % torch.cuda.device_count()
    world_size = cfg['num_gpus']

    setup_dist(rank, local_rank, world_size, cfg['master_addr'], cfg['master_port'])
    torch.manual_seed(42)

    dataset = DummyDataset(N=cfg['dataset_size'], dim=cfg['dim'])
    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)
    dataloader = DataLoader(dataset, batch_size=cfg['batch_size'], sampler=sampler)

    model = SimpleDDPM(dim=cfg['dim']).to(local_rank)
    model = DDP(model, device_ids=[local_rank])
    optimizer = optim.Adam(model.parameters(), lr=cfg['lr'])
    criterion = nn.MSELoss()

    for epoch in range(cfg['epochs']):
        sampler.set_epoch(epoch)
        for batch_idx, batch in enumerate(dataloader):
            batch = batch.to(local_rank)
            optimizer.zero_grad()
            t = torch.randint(0, 10, (batch.size(0),), device=batch.device)
            output = model(batch, t)
            loss = criterion(output, batch)
            loss.backward() # 自动同步梯度
            optimizer.step()

            if rank == 0 and batch_idx % 10 == 0:
                print(f"Epoch {epoch} | Batch {batch_idx} | Loss {loss.item():.4f}")

    if rank == 0:
        torch.save(unwrap_dist(model).state_dict(), cfg['ckpt_path'])

if __name__ == "__main__":
    cfg = {
        'num_gpus': torch.cuda.device_count(),
        'batch_size': 16,
        'epochs': 2,
        'dataset_size': 1024,
        'dim': 16,
        'lr': 1e-3,
        'master_addr': '127.0.0.1',
        'master_port': '29500',
        'ckpt_path': 'ddpm_ckpt.pt'
    }

    mp.spawn(train_ddpm, args=(cfg,), nprocs=cfg['num_gpus'], join=True)    # 每一个有自己的train_ddpm函数
```
