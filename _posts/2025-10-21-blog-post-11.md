---
title: 'Wall-E'
date: 2025-10-21
permalink: /posts/2025/10/blog-post-11/
tags:

---

Wall-E
======

探究 LLM 能不能作为一个有效的 world model
gap between prior knowledge of LLMs and the specified environment’s dynamics
通过在大型语言模型上进行规则学习, 可以高效实现LLM与其部署环境的对齐, 这种 “世界对齐” 过程。

model-predictive control

![wall-e](https://worfsmile.github.io//assets/images/2025-10-21-blog-post-11/image.png)

MPC:
(模型固定, 控制在变)
x_real(t) ─► 优化控制序列 u_t ─► 执行第一个动作 ─► 再测x_real(t+1) ─► 再优化

Online Learning:
(模型在变, 决策策略随模型变)
样本 (x_t, y_t) ─► 更新参数 θ_t ─► 预测下一个 y_{t+1} ─► 再更新 θ_{t+1}
