---
title: 'openVLA'
date: 2025-10-19
permalink: /posts/2025/10/blog-post-9/
tags:

---

VLA研究的内容
======

1. 机器人动作序列的预测
   1. 如何将VLM用到机器人动作预测上
      1. token设计
      2. 架构设计
      3. 等等
   2. 如何让训练更加鲁棒
      1. 预训练
      2. 损失设计
      3. 等等
   3. 新场景
      1. 时序
      2. 在线学习
      3. 等等

world model研究内容
======

3D世界的建模
指令行动决策

openVLA
======

![openVLA](https://worfsmile.github.io//assets/images/2025-10-19-blog-post-9/image.png)

把机器人动作作为离散标签, 把预训练视觉-语言模型微调, 使其在给定图像和语言指令时预测对应动作序列。

为什么离散化
LLM 就可以像预测文字一样预测动作序列

- 输入: 图像, 语言指令
- 架构: transformer next token prediction
- 输出: 动作序列
- 监督: 输出七个维度但是每个维度都有一个概率分布，进行交叉熵

- 输入: 用dinov2和SigLip提取图像信息, 用Llama提取语言信息后一起输入Llama2

在这个架构中有一个很明显的问题是, 这个输入和真实环境差距好像有点大

注意论文的行文架构
