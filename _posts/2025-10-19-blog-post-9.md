---
title: 'openVLA'
date: 2025-10-19
permalink: /posts/2025/10/blog-post-9/
tags:

---

VLA研究的内容
======

1. 机器人动作序列的预测
   1. 如何将VLM用到机器人动作预测上
      1. token设计
      2. 架构设计
      3. 等等
   2. 如何让训练更加鲁棒
      1. 预训练
      2. 损失设计
      3. 等等
   3. 新场景
      1. 时序
      2. 在线学习
      3. 等等

world model研究内容
======

3D世界的建模
指令行动决策

- 生成模型
- 强化学习
- 模仿学习
- VLA
- 等等

IR-L0: 专注于执行高度重复、机械化、确定性的任务, 例如工业焊接和固定路径物料搬运。
IR-L1: 它们无法处理复杂或不可预见的事件, 并且只能在具有明确规则的封闭任务环境中表现出操作稳定性。
IR-L2: 包括对环境变化的基本响应能力以及在多种任务模式之间切换的能力。
IR-L3: 系统可以推断用户意图, 并相应地调整其行为, 并在既定的伦理约束范围内运行。
IR-L4: 拥有自我进化的伦理推理能力、高级认知能力、同理心和长期自适应学习能力

- 模型预测控制是一种基于优化的方法, 它使用动态模型预测系统的未来行为, 并通过在每个时间步求解优化问题来计算控制动作
- 全身控制的基本方法通常包括将机器人的运动和力目标制定为一组优先任务
- 强化学习, 智能体可以通过与环境交互并接收奖励或惩罚形式的反馈来学习执行复杂任务
- 模仿学习通过观察和模仿通常由人类或其他智能体提供的演示来学习执行任务
- 将机器人控制指令离散化为类似语言的 tokens, 实现端到端的 VLA 映射。

场景

- 复杂的自然或人造地形上行动
- 快速行动
- 摔倒恢复
- 机器人操作
  - 双指夹取
  - 全身行动
- 人机交互
- 社会嵌入
- 机器人仿真

世界模型

使智能体能够预测未来状态并规划行动, 模拟人类导航和与环境互动的认知过程

展现形式

- 视频生成模型
- 3D生成模型

理解世界

- 可控模拟
- 多目标学习

openVLA
======

![openVLA](https://worfsmile.github.io//assets/images/2025-10-19-blog-post-9/image.png)

把机器人动作作为离散标签, 把预训练视觉-语言模型微调, 使其在给定图像和语言指令时预测对应动作序列。

为什么离散化
LLM 就可以像预测文字一样预测动作序列

- 输入: 图像, 语言指令
- 架构: transformer next token prediction
- 输出: 动作序列
- 监督: 输出七个维度但是每个维度都有一个概率分布, 进行交叉熵

- 输入: 用dinov2和SigLip提取图像信息, 用Llama提取语言信息后一起输入Llama2

在这个架构中有一个很明显的问题是, 这个输入和真实环境差距好像有点大

注意论文的行文架构
