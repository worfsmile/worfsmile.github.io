# Graph and Set â… 

## the blueprint of geometric deep learning

equivariant $\rarr$ local pooling layer $\rarr$ equivariant layer $\rarr$ invariant global pooling

## Learning on sets

$$
X = (x_1, ..., x_n)^T
$$

basic intuition:

we want to run nerual network on the set, which the permutation makes no sence.

permutation matrix

group action

### invariance

$$
f(PX)=f(X)
$$

then the function $f$ is permutation invariance

Deep Sets model
$$
f(X)=\phi(\oplus_{i\in V}\Phi(x_i))
$$

### equivariance

$$
PF(X)=F(PX)
$$

where $F$ means matrix

node level with edge relation

preserve inner relationship in the data

### locality

local average pooling



### General blueprint for learning on sets

$$
f(X) = \phi(\oplus_{i\in V}\Phi(x_i))
$$

## Learning on graph

the main difference between learning on graph and learning on set is permutation also act on the edges.

### invariance

$$
f(PX,PAP^T)=f(X,A)
$$

### equivariance

$$
F(PX,PAP^T)=PF(X,A)
$$

### locality:neighbourhoods

$$
\mathcal{N}_i=\{j:(i,j)\in\epsilon\ or (j,i)\in\epsilon\}
$$



## how to build function

what is $\phi$?

- diffusion
- propagation
- message passing

#### three flavours

- convolutional
  - useful in homophilous graph
  - weights depend on $A$
  - ChebyNet
  - GCN
  - SGC
- attentional
  - attention is computed as $\alpha_{ij}=a(x_i,x_j)$
  - useful as middle ground
  - MoNet
  - GAT
  - GATv2
- message-passing
  - messages computed as $m_{ij}=\Phi(x_i,x_j)$
  - Interaction Nets
  - MPNN
  - GraphNets



## some keys

- sample nodes